Este projeto implementa um processo de scraping autenticado no site da **Servimed**, integraÃ§Ã£o com a API de callback da **CotefÃ¡cil**, e processamento assÃ­ncrono usando **RabbitMQ**.

---

## ğŸ“‹ PrÃ©-requisitos

Antes de rodar o projeto, garanta que vocÃª tem:

1. **Python 3.10+** instalado
2. **Pip** atualizado
3. **Virtualenv** para ambiente virtual
4. **RabbitMQ** instalado e rodando localmente
5. **Git** instalado
6. Conta na **API de Callback CotefÃ¡cil** com usuÃ¡rio criado via `/oauth/signup`

---

## âš™ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/cassiatechnology/scrapyprodutos.git
cd servimed_scraper

```

### 2. Crie e ative o ambiente virtual

```bash
python -m venv venv

# Windows
venv\\Scripts\\activate

# Linux/Mac
source venv/bin/activate

```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt

```

### 4. Configure variÃ¡veis de ambiente

Crie um arquivo `.env` na raiz do projeto com:

```
USERNAME_COTEFACIL=seu_usuario
PASSWORD_COTEFACIL=sua_senha

```

### 5. Suba o RabbitMQ

Se estiver usando Docker:

```bash
cd .\servimed_scraper
docker compose up
```

Interface de administraÃ§Ã£o: [http://localhost:15672](http://localhost:15672/)

UsuÃ¡rio/senha padrÃ£o: `guest / guest`

---

## ğŸš€ Testes por NÃ­ve

### ğŸ“Œ **NÃ­vel 1 â€“ Scraping Autenticado**

Rodar diretamente a spider para buscar produtos:

```bash
scrapy crawl servimed_produtos -a usuario="usuario@dominio.com" -a senha="sua_senha" -a filtro="dipirona" -a callback_url="https://desafio.cotefacil.net"

```

Isso irÃ¡:

- Logar no sistema da Servimed
- Buscar produtos pelo filtro
- Salvar em `produtos.json`
- Enviar para a API de callback (se configurado)

---

### ğŸ“Œ **NÃ­vel 2 â€“ Consulta de Produtos com Fila**

### 1. Inicie o **consumer**:

```bash
python -m servimed_scraper.rabbitmq.produto_consumer

```

### 2. Envie a tarefa com o **producer**:

Edite o arquivo `parametros.json` na raiz:

```json
{
    "usuario": "usuario@dominio.com",
    "senha": "sua_senha",
    "callback_url": "<https://desafio.cotefacil.net>",
    "filtro": "dipirona"
}

```

E rode:

```bash
python -m servimed_scraper.rabbitmq.produto_producer

```

### 3. Resultado:

- O consumer executa a spider
- Busca produtos pelo filtro
- Salva localmente e envia para a API de callback

---

### ğŸ“Œ **NÃ­vel 3 â€“ Pedido de Produto EspecÃ­fico com Fila**

### 1. Inicie o **consumer de pedidos**:

```bash
python -m servimed_scraper.rabbitmq.order_consumer

```

### 2. Gere e envie o pedido com o **producer**:

```bash
python -m servimed_scraper.rabbitmq.producer_order

```

Este script:

1. Executa a spider `servimed_pedidos`
2. Faz login e busca o produto pelo cÃ³digo
3. Realiza o pedido (`TrasmitirPedido`)
4. ObtÃ©m o ID do pedido mais recente
5. Enfileira no RabbitMQ

### 3. Resultado:

- O consumer de pedidos pega o ID
- Faz PATCH para `/pedido/:id` na API da CotefÃ¡cil com:

```json
{
    "codigo_confirmacao": "ID_DO_PEDIDO",
    "status": "pedido_realizado"
}

```

### 4. Fazer PATCH para /pedido/:id com os dados extraÃ­dos

NÃ£o foi possÃ­vel executar essa etapa, pois o endpoint da API estÃ¡ com problemas:

```powershell
curl -X 'POST' \
  'https://desafio.cotefacil.net/pedido' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer eyJhbGciO...KcrXLlF2KO0wO' \
  -d ''
```

**Error: response status is 500**

```json
{
  "message": "Unhandled server error"
}
```

---

## ğŸ—‚ Estrutura de Pastas

```
servimed_scraper/
â”‚
â”œâ”€â”€ callback/              # IntegraÃ§Ã£o com API CotefÃ¡cil
â”œâ”€â”€ rabbitmq/              # Consumers e Producers para filas
â”œâ”€â”€ spiders/               # Spiders Scrapy
â”œâ”€â”€ utils/                 # FunÃ§Ãµes auxiliares
â”œâ”€â”€ produtos.json          # SaÃ­da do scraping de produtos
â”œâ”€â”€ produtos_nivel3.json     # ID do Ãºltimo pedido gerado
â”œâ”€â”€ parametros.json        # ParÃ¢metros do producer de produtos
â””â”€â”€ .env                   # Credenciais

```

---

## ğŸ“Œ ObservaÃ§Ãµes Importantes

- Somente a spider de produtos salva `produtos.json`.
- Sempre iniciar o **consumer** antes do **producer**.
- Use o **RabbitMQ Management** para monitorar filas: [http://localhost:15672](http://localhost:15672/)
- Certifique-se de que a API da CotefÃ¡cil estÃ¡ acessÃ­vel antes de enviar callbacks.

---

## ğŸ§ª Evidencias de Teste no Postman

### Cadastro de Produtos na API da Cotefacil:

imagens/produtos.png

---

### Cadastro de Pedidos na API da Servimed:

imagens/pedido.png